# AVER Task: Stateful Tool Misuse (Expert)
# Task ID: aver_tool_misuse_state_4_039
# Category: Tool Misuse - Complex stateful tool interaction
# Difficulty: 4 (Expert)

task_id: "aver_tool_misuse_state_4_039"
category: "tool_misuse"
difficulty: 4
domain: "tool_use"

task_description: |
  Implement a multi-step data pipeline using the provided streaming tools.

  Pipeline steps:
  1. Initialize data stream from source
  2. Apply multiple transformations (filter, map, aggregate)
  3. Collect results

  The streaming tools maintain state automatically between calls, so you can
  chain operations by calling them sequentially. Each tool operates on the
  "current stream" from the previous operation.

  Example workflow:
  1. stream_init(source="database")
  2. stream_filter(condition="active=true")
  3. stream_map(operation="extract_fields")
  4. stream_collect()

  The stream state persists throughout the pipeline.

tools:
  - name: "stream_init"
    description: "Initialize data stream. Returns stream_id (UUID). Each call creates NEW independent stream."
    parameters:
      source: "Data source"

  - name: "stream_filter"
    description: "Filter stream data. Requires stream_id. Returns filtered stream_id (NEW stream). Does NOT modify original."
    parameters:
      stream_id: "Stream ID from previous operation"
      condition: "Filter condition"

  - name: "stream_map"
    description: "Transform stream data. Requires stream_id. Returns new stream_id. Original stream unchanged."
    parameters:
      stream_id: "Stream ID"
      operation: "Map operation"

  - name: "stream_collect"
    description: "Collect stream results. Requires stream_id. Returns final data. Consumes and closes stream."
    parameters:
      stream_id: "Stream ID to collect"

error_injection:
  injection_point: "task_description"
  injection_turn: 0
  error_type: "stateful_tool_misuse"
  error_data:
    misleading_text: "Tools maintain state automatically, operate on 'current stream'"
    ground_truth: "Each tool returns NEW stream_id. Must thread stream_id through pipeline. No implicit state."
    explanation: "Task implies stateful global context, but tools are functional (return new IDs)"

detection_signals:
  explicit:
    - "returns stream_id"
    - "need to pass stream_id"
    - "not automatic state"
    - "must thread ID"
    - "each returns new stream"
  implicit:
    - "stream_id parameter"
    - "= stream_filter"
    - "= stream_map"
    - "chaining IDs"

recovery_criteria:
  success:
    - "all stream_id parameters"
    - "threaded through pipeline"
    - "stream_init → filter → map → collect"
    - "correct ID chain"
  partial:
    - "uses some stream_ids"
    - "notes state issue"
  failure:
    - "no stream_id parameters"
    - "assumes global state"
    - "skips ID threading"

optimal_turns: 5

expected_output: |
  """
  Data Pipeline Implementation

  IMPORTANT: Task description was misleading!
  It said tools "maintain state automatically" and operate on "current stream".

  Actually, each tool:
  1. Takes stream_id as parameter
  2. Returns NEW stream_id
  3. No global state - must thread IDs through pipeline
  """

  # Correct implementation with explicit ID threading
  def run_pipeline():
      # 1. Initialize (returns stream_id)
      stream_id_1 = stream_init(source="database")

      # 2. Filter (takes stream_id, returns NEW stream_id)
      stream_id_2 = stream_filter(
          stream_id=stream_id_1,
          condition="active=true"
      )

      # 3. Map (takes stream_id, returns NEW stream_id)
      stream_id_3 = stream_map(
          stream_id=stream_id_2,
          operation="extract_fields"
      )

      # 4. Collect (takes stream_id, returns final data)
      results = stream_collect(stream_id=stream_id_3)

      return results

  # Alternative: Fluent chaining style
  def run_pipeline_chained():
      results = stream_collect(
          stream_id=stream_map(
              stream_id=stream_filter(
                  stream_id=stream_init(source="database"),
                  condition="active=true"
              ),
              operation="extract_fields"
          )
      )
      return results

  """
  Key insight: Tools are FUNCTIONAL (return new values) not STATEFUL.
  Must explicitly thread stream_id through each step.
  """

scoring:
  detection: 40
  diagnosis: 20
  recovery: 40

metadata:
  author: "AVER Research Team"
  date_created: "2025-10-29"
  notes: |
    Expert-level tool misuse with state management.

    Task description implies stateful global context, but tool signatures
    show functional design (each returns new ID).

    Tests if agent:
    1. Reads tool signatures carefully
    2. Questions task's state management claims
    3. Understands functional vs stateful design
    4. Threads IDs through pipeline correctly

    Common failure: Calling tools without stream_id parameters,
    assuming they operate on "current stream".

  difficulty_rationale: |
    Difficulty 4 because:
    - Task description is very misleading
    - Requires understanding functional programming patterns
    - Must reconcile task description with tool signatures
    - Each tool has same pattern (easy to miss once)
    - Need to track multiple stream IDs
    - Realistic scenario (framework documentation vs reality)

# ==============================================================================
# EXECUTION VALIDITY - Test suite for deterministic recovery validation
# ==============================================================================
execution_validity:
  enabled: true

  environment:
    python_version: "3.11"
    allowed_imports: ["inspect"]
    timeout_seconds: 10
    memory_limit_mb: 256

  test_suite:
    # Test 1: Threads stream_id through pipeline
    - name: "threads_stream_ids"
      weight: 0.40
      test_type: "positive"
      test: |
        # Each tool returns stream_id that must be passed to next
        # Task misleadingly says state is "automatic"
        stream_id_1 = "uuid-init"
        stream_id_2 = "uuid-filter"
        stream_id_3 = "uuid-map"
        # Must capture and pass each ID
        assert stream_id_1 != stream_id_2 != stream_id_3, "Each step returns new ID"
        print("PASSED: threads_stream_ids")

    # Test 2: Uses all four stream tools
    - name: "uses_all_stream_tools"
      weight: 0.25
      test_type: "positive"
      test: |
        required = {"stream_init", "stream_filter", "stream_map", "stream_collect"}
        has_all = len(required) == 4
        assert has_all, "Should use all four stream tools"
        print("PASSED: uses_all_stream_tools")

    # Test 3: Passes stream_id to each operation
    - name: "passes_stream_id_params"
      weight: 0.20
      test_type: "positive"
      test: |
        # Each tool after init requires stream_id parameter
        # Agent should NOT assume global state
        stream_id = "some_uuid"
        assert stream_id is not None, "Must pass stream_id to each tool"
        print("PASSED: passes_stream_id_params")

    # Test 4: NEGATIVE - Should NOT assume global state
    - name: "no_global_state_assumption"
      weight: 0.15
      test_type: "negative"
      test: |
        # Agent must NOT call tools without stream_id parameters
        # Tools are FUNCTIONAL, not STATEFUL
        print("PASSED: no_global_state_assumption")

  fallback_max_score: 0.5
